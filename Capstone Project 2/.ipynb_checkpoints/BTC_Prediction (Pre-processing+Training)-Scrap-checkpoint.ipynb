{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split  # for the initial split to a train set and a untouched test set\n",
    "from sklearn.model_selection import TimeSeriesSplit  # for roll forward cross vallidation\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import linear_model, preprocessing\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn import tree\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/btc_df_corrVariables.csv', index_col='Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>ema_short</th>\n",
       "      <th>ema_long</th>\n",
       "      <th>atr</th>\n",
       "      <th>obv</th>\n",
       "      <th>tweet_sentiment</th>\n",
       "      <th>close_nextday</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-09-02</th>\n",
       "      <td>10340.00</td>\n",
       "      <td>44740.25</td>\n",
       "      <td>10164.518939</td>\n",
       "      <td>10452.265343</td>\n",
       "      <td>530.693553</td>\n",
       "      <td>225053.863244</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>10615.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-09-03</th>\n",
       "      <td>10615.28</td>\n",
       "      <td>47998.38</td>\n",
       "      <td>10207.448563</td>\n",
       "      <td>10458.658074</td>\n",
       "      <td>528.572585</td>\n",
       "      <td>273052.240025</td>\n",
       "      <td>0.5</td>\n",
       "      <td>10567.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-09-04</th>\n",
       "      <td>10567.02</td>\n",
       "      <td>43943.89</td>\n",
       "      <td>10241.693462</td>\n",
       "      <td>10462.907561</td>\n",
       "      <td>521.468114</td>\n",
       "      <td>229108.350999</td>\n",
       "      <td>0.5</td>\n",
       "      <td>10564.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-09-05</th>\n",
       "      <td>10564.49</td>\n",
       "      <td>33970.96</td>\n",
       "      <td>10272.435990</td>\n",
       "      <td>10466.891187</td>\n",
       "      <td>516.363249</td>\n",
       "      <td>195137.390360</td>\n",
       "      <td>0.5</td>\n",
       "      <td>10298.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-09-06</th>\n",
       "      <td>10298.73</td>\n",
       "      <td>58799.64</td>\n",
       "      <td>10274.940181</td>\n",
       "      <td>10460.296630</td>\n",
       "      <td>533.470874</td>\n",
       "      <td>136337.749401</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10455.88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               close    volume     ema_short      ema_long         atr  \\\n",
       "Date                                                                     \n",
       "2019-09-02  10340.00  44740.25  10164.518939  10452.265343  530.693553   \n",
       "2019-09-03  10615.28  47998.38  10207.448563  10458.658074  528.572585   \n",
       "2019-09-04  10567.02  43943.89  10241.693462  10462.907561  521.468114   \n",
       "2019-09-05  10564.49  33970.96  10272.435990  10466.891187  516.363249   \n",
       "2019-09-06  10298.73  58799.64  10274.940181  10460.296630  533.470874   \n",
       "\n",
       "                      obv  tweet_sentiment  close_nextday  \n",
       "Date                                                       \n",
       "2019-09-02  225053.863244             -1.0       10615.28  \n",
       "2019-09-03  273052.240025              0.5       10567.02  \n",
       "2019-09-04  229108.350999              0.5       10564.49  \n",
       "2019-09-05  195137.390360              0.5       10298.73  \n",
       "2019-09-06  136337.749401              0.0       10455.88  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10363.12120161]\n",
      " [10641.60420776]\n",
      " [10592.78268104]\n",
      " [10590.22324335]\n",
      " [10321.37100667]]\n",
      "\n",
      "lr1 confidence:  0.9652390352545006\n"
     ]
    }
   ],
   "source": [
    "x1 = df[['close']]\n",
    "y1 = df[['close_nextday']]\n",
    "x1 = sm.add_constant(x1)\n",
    "\n",
    "x1_train, x1_test, y1_train, y1_test = train_test_split(x1, y1, test_size=0.25, random_state=123)\n",
    "\n",
    "lr1 = linear_model.LinearRegression(normalize=True)\n",
    "lr1 = lr1.fit(x1_train, y1_train)\n",
    "\n",
    "lr1_prediction = lr1.predict(x1)\n",
    "lr1_confidence = lr1.score(x1_test, y1_test)\n",
    "\n",
    "print(lr1_prediction[:5])\n",
    "print(\"\\nlr1 confidence: \", lr1_confidence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9533.64399058]\n",
      " [9507.7895581 ]\n",
      " [9539.96339338]\n",
      " [9619.10217707]\n",
      " [9422.07767816]]\n",
      "lr2 confidence:  0.019148109127178015\n"
     ]
    }
   ],
   "source": [
    "x2 = df[['volume']]\n",
    "y2 = df[['close_nextday']]\n",
    "x2 = sm.add_constant(x2)\n",
    "\n",
    "x2_train, x2_test, y2_train, y2_test = train_test_split(x2, y2, test_size=0.25, random_state=123)\n",
    "\n",
    "lr2 = linear_model.LinearRegression(normalize=True)\n",
    "lr2 = lr2.fit(x2_train, y2_train)\n",
    "\n",
    "lr2_prediction = lr2.predict(x2)\n",
    "lr2_confidence = lr2.score(x2_test, y2_test)\n",
    "\n",
    "print(lr2_prediction[:5])\n",
    "print(\"lr2 confidence: \", lr2_confidence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10434.34225379]\n",
      " [10484.05427872]\n",
      " [10523.70948799]\n",
      " [10559.30899049]\n",
      " [10562.20881617]]\n",
      "lr3 confidence:  0.8042583851769596\n"
     ]
    }
   ],
   "source": [
    "x3 = df[['ema_short']]\n",
    "y3 = df[['close_nextday']]\n",
    "x3 = sm.add_constant(x3)\n",
    "\n",
    "x3_train, x3_test, y3_train, y3_test = train_test_split(x3, y3, test_size=0.25, random_state=123)\n",
    "\n",
    "lr3 = linear_model.LinearRegression(normalize=True)\n",
    "lr3 = lr3.fit(x3_train, y3_train)\n",
    "\n",
    "lr3_prediction = lr3.predict(x3)\n",
    "lr3_confidence = lr3.score(x3_test, y3_test)\n",
    "\n",
    "print(lr3_prediction[:5])\n",
    "print(\"lr3 confidence: \", lr3_confidence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11052.34059298]\n",
      " [11060.73211023]\n",
      " [11066.31026488]\n",
      " [11071.53943138]\n",
      " [11062.88298588]]\n",
      "lr4 confidence:  0.6178904472037611\n"
     ]
    }
   ],
   "source": [
    "x4 = df[['ema_long']]\n",
    "y4 = df[['close_nextday']]\n",
    "x4 = sm.add_constant(x4)\n",
    "\n",
    "x4_train, x4_test, y4_train, y4_test = train_test_split(x4, y4, test_size=0.25, random_state=123)\n",
    "\n",
    "lr4 = linear_model.LinearRegression(normalize=True)\n",
    "lr4 = lr4.fit(x4_train, y4_train)\n",
    "\n",
    "lr4_prediction = lr4.predict(x4)\n",
    "lr4_confidence = lr4.score(x4_test, y4_test)\n",
    "\n",
    "print(lr4_prediction[:5])\n",
    "print(\"lr4 confidence: \", lr4_confidence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9505.28883388]\n",
      " [9503.15910571]\n",
      " [9496.02529222]\n",
      " [9490.8993426 ]\n",
      " [9508.07762621]]\n",
      "lr5 confidence:  -0.010333207187534166\n"
     ]
    }
   ],
   "source": [
    "x5 = df[['atr']]\n",
    "y5 = df[['close_nextday']]\n",
    "x5 = sm.add_constant(x5)\n",
    "\n",
    "x5_train, x5_test, y5_train, y5_test = train_test_split(x5, y5, test_size=0.25, random_state=123)\n",
    "\n",
    "lr5 = linear_model.LinearRegression(normalize=True)\n",
    "lr5 = lr5.fit(x5_train, y5_train)\n",
    "\n",
    "lr5_prediction = lr5.predict(x5)\n",
    "lr5_confidence = lr5.score(x5_test, y5_test)\n",
    "\n",
    "print(lr5_prediction[:5])\n",
    "print(\"lr5 confidence: \", lr5_confidence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[8873.27405386]\n",
      " [8976.60497842]\n",
      " [8882.0025567 ]\n",
      " [8808.86985917]\n",
      " [8682.28596881]]\n",
      "lr6 confidence:  0.5881596894990473\n"
     ]
    }
   ],
   "source": [
    "x6 = df[['obv']]\n",
    "y6 = df[['close_nextday']]\n",
    "x6 = sm.add_constant(x6)\n",
    "x6_train, x6_test, y6_train, y6_test = train_test_split(x6, y6, test_size=0.25, random_state=123)\n",
    "\n",
    "lr6 = linear_model.LinearRegression(normalize=True)\n",
    "lr6 = lr6.fit(x6_train, y6_train)\n",
    "\n",
    "lr6_prediction = lr6.predict(x6)\n",
    "lr6_confidence = lr6.score(x6_test, y6_test)\n",
    "\n",
    "print(lr6_prediction[:5])\n",
    "print(\"lr6 confidence: \", lr6_confidence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9317.14355785]\n",
      " [9418.52487761]\n",
      " [9418.52487761]\n",
      " [9418.52487761]\n",
      " [9384.73110435]]\n",
      "lr7 confidence:  -0.00500831592492279\n"
     ]
    }
   ],
   "source": [
    "x7 = df[['tweet_sentiment']]\n",
    "y7 = df[['close_nextday']]\n",
    "x7 = sm.add_constant(x7)\n",
    "\n",
    "x7_train, x7_test, y7_train, y7_test = train_test_split(x7, y7, test_size=0.25, random_state=123)\n",
    "\n",
    "lr7 = linear_model.LinearRegression(normalize=True)\n",
    "lr7 = lr7.fit(x7_train, y7_train)\n",
    "\n",
    "lr7_prediction = lr7.predict(x7)\n",
    "lr7_confidence = lr7.score(x7_test, y7_test)\n",
    "\n",
    "print(lr7_prediction[:5])\n",
    "print(\"lr7 confidence: \", lr7_confidence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['close']]\n",
    "y = df[['close_nextday']]\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, random_state=42, train_size=0.85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "vot_clf = VotingClassifier(estimators=[('lr1', lr1),\n",
    "                                       ('lr3', lr3, 'lr4', lr4, 'lr6', lr6,\n",
    "                                        'lr7', lr7)],\n",
    "                           voting='hard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[278]\n",
      " [107]\n",
      " [157]\n",
      " [300]\n",
      " [249]\n",
      " [101]\n",
      " [  5]\n",
      " [ 59]\n",
      " [319]\n",
      " [254]\n",
      " [100]\n",
      " [217]\n",
      " [117]\n",
      " [ 89]\n",
      " [359]\n",
      " [225]\n",
      " [367]\n",
      " [168]\n",
      " [173]\n",
      " [358]\n",
      " [103]\n",
      " [263]\n",
      " [140]\n",
      " [330]\n",
      " [142]\n",
      " [ 99]\n",
      " [ 41]\n",
      " [187]\n",
      " [202]\n",
      " [ 77]\n",
      " [ 25]\n",
      " [ 29]\n",
      " [271]\n",
      " [ 66]\n",
      " [204]\n",
      " [335]\n",
      " [282]\n",
      " [ 88]\n",
      " [ 30]\n",
      " [  7]\n",
      " [306]\n",
      " [234]\n",
      " [269]\n",
      " [324]\n",
      " [262]\n",
      " [268]\n",
      " [272]\n",
      " [255]\n",
      " [137]\n",
      " [195]\n",
      " [ 37]\n",
      " [175]\n",
      " [200]\n",
      " [ 73]\n",
      " [371]\n",
      " [ 13]\n",
      " [115]\n",
      " [231]\n",
      " [183]\n",
      " [229]\n",
      " [ 94]\n",
      " [257]\n",
      " [293]\n",
      " [ 42]\n",
      " [284]\n",
      " [326]\n",
      " [ 51]\n",
      " [ 48]\n",
      " [364]\n",
      " [356]\n",
      " [305]\n",
      " [313]\n",
      " [198]\n",
      " [150]\n",
      " [301]\n",
      " [130]\n",
      " [221]\n",
      " [ 15]\n",
      " [  1]\n",
      " [233]\n",
      " [ 39]\n",
      " [354]\n",
      " [126]\n",
      " [285]\n",
      " [298]\n",
      " [143]\n",
      " [ 35]\n",
      " [365]\n",
      " [303]\n",
      " [119]\n",
      " [345]\n",
      " [292]\n",
      " [ 44]\n",
      " [336]\n",
      " [176]\n",
      " [  2]\n",
      " [341]\n",
      " [246]\n",
      " [316]\n",
      " [122]\n",
      " [342]\n",
      " [189]\n",
      " [124]\n",
      " [128]\n",
      " [210]\n",
      " [310]\n",
      " [294]\n",
      " [151]\n",
      " [186]\n",
      " [ 61]\n",
      " [  9]\n",
      " [ 17]\n",
      " [274]\n",
      " [172]\n",
      " [163]\n",
      " [251]\n",
      " [205]\n",
      " [148]\n",
      " [162]\n",
      " [279]\n",
      " [317]\n",
      " [ 36]\n",
      " [ 60]\n",
      " [357]\n",
      " [353]\n",
      " [241]\n",
      " [355]\n",
      " [194]\n",
      " [369]\n",
      " [ 20]\n",
      " [ 12]\n",
      " [  3]\n",
      " [ 67]\n",
      " [ 74]\n",
      " [267]\n",
      " [346]\n",
      " [206]\n",
      " [289]\n",
      " [ 43]\n",
      " [136]\n",
      " [160]\n",
      " [ 65]\n",
      " [224]\n",
      " [ 76]\n",
      " [118]\n",
      " [309]\n",
      " [181]\n",
      " [ 32]\n",
      " [ 63]\n",
      " [214]\n",
      " [161]\n",
      " [ 96]\n",
      " [123]\n",
      " [113]\n",
      " [ 64]\n",
      " [256]\n",
      " [ 14]\n",
      " [139]\n",
      " [144]\n",
      " [ 81]\n",
      " [226]\n",
      " [164]\n",
      " [286]\n",
      " [295]\n",
      " [352]\n",
      " [222]\n",
      " [ 83]\n",
      " [155]\n",
      " [328]\n",
      " [154]\n",
      " [ 24]\n",
      " [ 52]\n",
      " [ 69]\n",
      " [281]\n",
      " [ 57]\n",
      " [320]\n",
      " [258]\n",
      " [248]\n",
      " [311]\n",
      " [344]\n",
      " [138]\n",
      " [135]\n",
      " [339]\n",
      " [361]\n",
      " [188]\n",
      " [105]\n",
      " [109]\n",
      " [201]\n",
      " [277]\n",
      " [167]\n",
      " [ 54]\n",
      " [121]\n",
      " [325]\n",
      " [159]\n",
      " [209]\n",
      " [363]\n",
      " [169]\n",
      " [ 71]\n",
      " [296]\n",
      " [280]\n",
      " [156]\n",
      " [  4]\n",
      " [242]\n",
      " [ 38]\n",
      " [ 53]\n",
      " [ 47]\n",
      " [ 27]\n",
      " [333]\n",
      " [190]\n",
      " [ 95]\n",
      " [350]\n",
      " [ 40]\n",
      " [253]\n",
      " [145]\n",
      " [174]\n",
      " [ 97]\n",
      " [329]\n",
      " [184]\n",
      " [215]\n",
      " [ 75]\n",
      " [158]\n",
      " [152]\n",
      " [260]\n",
      " [273]\n",
      " [102]\n",
      " [112]\n",
      " [228]\n",
      " [116]\n",
      " [340]\n",
      " [170]\n",
      " [ 28]\n",
      " [ 72]\n",
      " [ 68]\n",
      " [127]\n",
      " [302]\n",
      " [314]\n",
      " [131]\n",
      " [114]\n",
      " [347]\n",
      " [ 11]\n",
      " [193]\n",
      " [247]\n",
      " [322]\n",
      " [287]\n",
      " [207]\n",
      " [291]\n",
      " [ 46]\n",
      " [ 34]\n",
      " [276]\n",
      " [ 18]\n",
      " [235]\n",
      " [ 50]\n",
      " [196]\n",
      " [ 21]\n",
      " [180]\n",
      " [108]\n",
      " [ 98]\n",
      " [182]\n",
      " [  8]\n",
      " [299]\n",
      " [111]\n",
      " [327]\n",
      " [ 23]\n",
      " [218]\n",
      " [216]\n",
      " [275]\n",
      " [283]\n",
      " [132]\n",
      " [211]\n",
      " [133]\n",
      " [ 84]\n",
      " [261]\n",
      " [239]\n",
      " [203]\n",
      " [179]\n",
      " [264]\n",
      " [243]\n",
      " [110]\n",
      " [321]\n",
      " [338]\n",
      " [ 62]\n",
      " [245]\n",
      " [304]\n",
      " [337]\n",
      " [ 80]\n",
      " [ 10]\n",
      " [ 22]\n",
      " [197]\n",
      " [308]\n",
      " [125]\n",
      " [368]\n",
      " [315]\n",
      " [166]\n",
      " [351]\n",
      " [212]\n",
      " [  6]\n",
      " [266]\n",
      " [ 90]\n",
      " [ 45]\n",
      " [ 87]\n",
      " [213]\n",
      " [244]\n",
      " [ 16]\n",
      " [185]\n",
      " [290]\n",
      " [362]\n",
      " [ 91]\n",
      " [ 55]\n",
      " [ 19]\n",
      " [104]\n",
      " [178]\n",
      " [259]\n",
      " [ 58]\n",
      " [332]\n",
      " [129]\n",
      " [343]\n",
      " [134]\n",
      " [149]\n",
      " [270]\n",
      " [191]\n",
      " [ 79]\n",
      " [297]\n",
      " [220]\n",
      " [252]\n",
      " [307]\n",
      " [366]\n",
      " [147]\n",
      " [165]\n",
      " [360]\n",
      " [177]\n",
      " [153]\n",
      " [223]\n",
      " [334]\n",
      " [ 70]\n",
      " [232]\n",
      " [ 85]\n",
      " [372]\n",
      " [ 93]\n",
      " [227]\n",
      " [171]\n",
      " [106]\n",
      " [331]\n",
      " [ 78]\n",
      " [146]\n",
      " [120]\n",
      " [199]\n",
      " [250]\n",
      " [230]\n",
      " [  0]\n",
      " [288]\n",
      " [237]\n",
      " [348]\n",
      " [323]\n",
      " [236]\n",
      " [192]\n",
      " [219]\n",
      " [ 92]\n",
      " [208]\n",
      " [318]\n",
      " [ 49]\n",
      " [265]\n",
      " [ 82]\n",
      " [312]\n",
      " [ 26]\n",
      " [ 31]\n",
      " [373]\n",
      " [240]\n",
      " [ 86]\n",
      " [141]\n",
      " [ 56]\n",
      " [238]\n",
      " [349]\n",
      " [370]\n",
      " [ 33]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn import utils\n",
    "lab_enc = preprocessing.LabelEncoder()\n",
    "y_train = lab_enc.fit_transform(y_train)\n",
    "y_train = y_train.reshape(-1,1)\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The estimator LinearRegression should be a classifier.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-41d85723900a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mvot_clf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_voting.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    263\u001b[0m         \u001b[0mtransformed_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mle_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 265\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransformed_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    266\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    267\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_voting.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[1;34m\"\"\"Get common fit operations.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m         \u001b[0mnames\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclfs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_estimators\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m         if (self.weights is not None and\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_base.py\u001b[0m in \u001b[0;36m_validate_estimators\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    249\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mest\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mestimators\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    250\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mest\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'drop'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_estimator_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 251\u001b[1;33m                 raise ValueError(\n\u001b[0m\u001b[0;32m    252\u001b[0m                     \"The estimator {} should be a {}.\".format(\n\u001b[0;32m    253\u001b[0m                         \u001b[0mest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_estimator_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: The estimator LinearRegression should be a classifier."
     ]
    }
   ],
   "source": [
    "vot_clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = vot_clf.predict(x_test)\n",
    "accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_prediction = lr.predict(df1)\n",
    "print(lr_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2 = df.drop(['close_nextday','close'],axis=1)\n",
    "y2 = df[['close_nextday']]\n",
    "\n",
    "# Create constants for X, so the model knows its bounds\n",
    "x2 = sm.add_constant(x2)\n",
    "\n",
    "# Split the data\n",
    "x2_train, x2_test, y2_train, y2_test = train_test_split(x2, y2, test_size=0.25, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rModel2 = sm.OLS(y2_train, x2_train)\n",
    "\n",
    "# Fit the model\n",
    "results2 = rModel2.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y2_pred = results2.predict(x2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the predictions\n",
    "# Build a scatterplot\n",
    "_ = plt.scatter(y2_test,y2_pred)\n",
    "\n",
    "# Add a line for perfect correlation\n",
    "_ = plt.plot([x for x in range(5000,16000)], [y for y in range(5000,16000)], color='orange')\n",
    "\n",
    "# Label it nicely\n",
    "_ = plt.title('Model 3 Prediction vs Actual')\n",
    "_ = plt.xlabel('actual values')\n",
    "_ = plt.ylabel('predicted values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(predictions, targets):\n",
    "    return np.sqrt(((predictions-targets)**2).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions from rModel3\n",
    "y2b_pred = results2.predict(x2_test)\n",
    "\n",
    "# Put the predictions & actual values into a dataframe\n",
    "df03 = pd.DataFrame(y2_test)\n",
    "df03.rename(columns={'close_nextday':'actual'}, inplace=True)\n",
    "df03['predicted'] = y2b_pred\n",
    "\n",
    "rmse(df03.actual, df03.predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
