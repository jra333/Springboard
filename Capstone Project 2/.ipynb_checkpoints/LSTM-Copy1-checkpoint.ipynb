{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = read_csv('data/test.csv', index_col='Date')\n",
    "\n",
    "\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset = pd.concat([macd_data,close_data,], axis=1, sort=True).reindex(macd_data.index)\n",
    "close_data = dataset[['close']]\n",
    "close_data_check = close_data[int(y.shape[0] * 0.8):]\n",
    "\n",
    "print(close_data_check.shape)\n",
    "print(min(close_data_check['close']), max(close_data_check['close']))\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(close_data_check)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = dataset.drop(labels=['close_nextday'], axis=1)\n",
    "X = dataset.drop(labels=['close', 'close_nextday'], axis=1)\n",
    "y = dataset['close_nextday']\n",
    "\n",
    "print(X)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y=np.ravel(y)\n",
    "values_x = X.values\n",
    "values_y = y.values\n",
    "\n",
    "print(values_x)\n",
    "print(values_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values_y = values_y.reshape(-1,1)\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_data_X = scaler.fit_transform(values_x)\n",
    "scaled_data_y = scaler.fit_transform(values_y)\n",
    "\n",
    "print(scaled_data_X.shape)\n",
    "print(scaled_data_y.shape)\n",
    "\n",
    "X_train = scaled_data_X[:int(X.shape[0] * 0.8)]\n",
    "X_test = scaled_data_X[int(y.shape[0] * 0.8):]\n",
    "y_train = scaled_data_y[:int(X.shape[0] * 0.8)]\n",
    "y_test = scaled_data_y[int(y.shape[0] * 0.8):]\n",
    "\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "print(X_train.shape, X_train)\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], 1, X_train.shape[1])\n",
    "X_test = X_test.reshape(X_test.shape[0], 1, X_test.shape[1])\n",
    "y_train = y_train.reshape(y_train.shape[0], 1, 1)\n",
    "y_test = y_test.reshape(y_test.shape[0], 1, 1)\n",
    "\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_train, b_train, c_test, d_test = [], [], [], []\n",
    "for i in range(1, y_train.shape[0]):\n",
    "    a_train.append(X_train[i - 1:i, 0])\n",
    "    b_train.append(y_train[i, 0])\n",
    "for x in range(1, y_test.shape[0]):\n",
    "    c_test.append(X_test[x - 1:x, 0])\n",
    "    d_test.append(y_test[x, 0])\n",
    "\n",
    "a_train, b_train, c_test, d_test = np.array(a_train), np.array(\n",
    "    b_train), np.array(c_test), np.array(d_test)\n",
    "a_train = np.reshape(a_train, (a_train.shape[0], a_train.shape[1], 6))\n",
    "b_train = np.reshape(b_train, (b_train.shape[0], b_train.shape[1]))\n",
    "c_test = np.reshape(c_test, (c_test.shape[0], c_test.shape[1], 6))\n",
    "d_test = np.reshape(d_test, (d_test.shape[0], d_test.shape[1]))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(\n",
    "    LSTM(units=1000,\n",
    "         return_sequences=True,\n",
    "         input_shape=(a_train.shape[1], a_train.shape[2])))\n",
    "model.add(LSTM(units=1000))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "#ADAM = keras.optimizers.Adam(0.0005, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
    "#model.compile(loss='mean_squared_error', optimizer=ADAM)\n",
    "history = model.fit(a_train,\n",
    "                    b_train,\n",
    "                    epochs=100,\n",
    "                    batch_size=72,\n",
    "                    validation_data=(c_test, d_test),\n",
    "                    verbose=2,\n",
    "                    shuffle=False)\n",
    "\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "yhat = model.predict(c_test)\n",
    "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1]))\n",
    "inv_yhat = concatenate((yhat, X_test[1:, 1:]), axis=1)\n",
    "inv_yhat = scaler.inverse_transform(inv_yhat)\n",
    "inv_yhat = inv_yhat[:, 0]\n",
    "\n",
    "y_test = y_test.reshape((y_test.shape[0], y_test.shape[1]))\n",
    "inv_y = concatenate((y_test[1:], X_test[1:, 1:]), axis=1)\n",
    "inv_y = scaler.inverse_transform(inv_y)\n",
    "inv_y = inv_y[:, 0]\n",
    "rmse = np.sqrt(mean_squared_error(inv_y, inv_yhat))\n",
    "print('Test RMSE: %.3f' % rmse)\n",
    "\n",
    "_ = plt.figure(figsize=(10, 6))\n",
    "_ = plt.plot(inv_y)\n",
    "_ = plt.plot(inv_yhat)\n",
    "_ = plt.legend([\"actual\", \"pred\"])\n",
    "plt.show()\n",
    "\n",
    "print(min(inv_y), max(inv_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def mean_absolute_percentage_error(inv_y, inv_yhat):\n",
    "    inv_y, inv_yhat = np.array(inv_y), np.array(inv_yhat)\n",
    "    return np.mean(np.abs((inv_y - inv_yhat) / inv_y)) * 100\n",
    "\n",
    "mape = mean_absolute_percentage_error(inv_y, inv_yhat)\n",
    "mae = metrics.mean_absolute_error(inv_y, inv_yhat)\n",
    "mse = metrics.mean_squared_error(inv_y, inv_yhat)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print(\"Results of sklearn.metrics:\\n\")\n",
    "print(\"MAPE:\", mape)\n",
    "print(\"MAE:\", mae)\n",
    "print(\"MSE:\", mse)\n",
    "print(\"RMSE:\", rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(inv_y.shape)\n",
    "print(inv_yhat.shape)\n",
    "print(yhat.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from pandas import DataFrame\n",
    "from pandas import Series\n",
    "from pandas import concat\n",
    "from pandas import read_csv\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM\n",
    "import keras\n",
    "from math import sqrt\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import numpy\n",
    "from numpy import concatenate\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import metrics\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from hyperopt import Trials, STATUS_OK, tpe\n",
    "from keras.datasets import mnist\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.models import Sequential\n",
    "from keras.utils import np_utils\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "from hyperas import optim\n",
    "from hyperas.distributions import choice, uniform\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data():\n",
    "    \"\"\"\n",
    "    Data providing function:\n",
    "\n",
    "    This function is separated from create_model() so that hyperopt\n",
    "    won't reload data for each evaluation run.\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    dataset = read_csv('data/test.csv', index_col='Date')\n",
    "    X = dataset.drop(labels=['close', 'close_nextday'], axis=1)\n",
    "    y = dataset['close_nextday']\n",
    "    values_x = X.values\n",
    "    values_y = y.values\n",
    "    values_y = values_y.reshape(-1, 1)\n",
    "\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    scaled_data_X = scaler.fit_transform(values_x)\n",
    "    scaled_data_y = scaler.fit_transform(values_y)\n",
    "\n",
    "    X_train = scaled_data_X[:int(X.shape[0] * 0.8)]\n",
    "    X_test = scaled_data_X[int(y.shape[0] * 0.8):]\n",
    "    y_train = scaled_data_y[:int(X.shape[0] * 0.8)]\n",
    "    y_test = scaled_data_y[int(y.shape[0] * 0.8):]\n",
    "\n",
    "    X_train = np.array(X_train)\n",
    "    X_test = np.array(X_test)\n",
    "    y_train = np.array(y_train)\n",
    "    y_test = np.array(y_test)\n",
    "\n",
    "    X_train = X_train.reshape(X_train.shape[0], 1, X_train.shape[1])\n",
    "    X_test = X_test.reshape(X_test.shape[0], 1, X_test.shape[1])\n",
    "    y_train = y_train.reshape(y_train.shape[0], 1, 1)\n",
    "    y_test = y_test.reshape(y_test.shape[0], 1, 1)\n",
    "\n",
    "    a_train, b_train, c_test, d_test = [], [], [], []\n",
    "    for i in range(1, y_train.shape[0]):\n",
    "        a_train.append(X_train[i - 2:i, 0])\n",
    "        b_train.append(y_train[i, 0])\n",
    "    for x in range(1, y_test.shape[0]):\n",
    "        c_test.append(X_test[x - 2:x, 0])\n",
    "        d_test.append(y_test[x, 0])\n",
    "\n",
    "    a_train, b_train, c_test, d_test = np.array(a_train), np.array(\n",
    "        b_train), np.array(c_test), np.array(d_test)\n",
    "    a_train = np.reshape(a_train, (a_train.shape[0], a_train.shape[1], 6))\n",
    "    b_train = np.reshape(b_train, (b_train.shape[0], b_train.shape[1]))\n",
    "    c_test = np.reshape(c_test, (c_test.shape[0], c_test.shape[1], 6))\n",
    "    d_test = np.reshape(d_test, (d_test.shape[0], d_test.shape[1]))\n",
    "    \n",
    "    print(len(a_train), 'train sequences')\n",
    "    print(len(c_test), 'test sequences')\n",
    "\n",
    "    print(\"Pad sequences (samples x time)\")\n",
    "    a_train = sequence.pad_sequences(a_train, maxlen=maxlen)\n",
    "    c_test = sequence.pad_sequences(c_test, maxlen=maxlen)\n",
    "    print('a_train shape:', a_train.shape)\n",
    "    print('c_test shape:', c_test.shape)\n",
    "\n",
    "    \n",
    "    return a_train, b_train, c_test, d_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#maxlen = 441\n",
    "#max_features = 7\n",
    "\n",
    "\n",
    "#print(len(a_train), 'train sequences')\n",
    "#print(len(c_test), 'test sequences')\n",
    "\n",
    "#print(\"Pad sequences (samples x time)\")\n",
    "#a_train = sequence.pad_sequences(a_train, maxlen=maxlen)\n",
    "#c_test = sequence.pad_sequences(c_test, maxlen=maxlen)\n",
    "    #print('a_train shape:', a_train.shape)\n",
    "    #print('c_test shape:', c_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#model.add(Embedding(max_features, 128, input_length=maxlen))\n",
    "#validation_split=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<unknown>, line 484)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[1;36m(most recent call last)\u001b[0m:\n",
      "  File \u001b[0;32m\"C:\\Users\\aranc\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\interactiveshell.py\"\u001b[0m, line \u001b[0;32m3418\u001b[0m, in \u001b[0;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \u001b[0;32m\"<ipython-input-3-1e6f80c4796c>\"\u001b[0m, line \u001b[0;32m40\u001b[0m, in \u001b[0;35m<module>\u001b[0m\n    best_run, best_model = optim.minimize(model=create_model,\n",
      "  File \u001b[0;32m\"C:\\Users\\aranc\\AppData\\Roaming\\Python\\Python38\\site-packages\\hyperas\\optim.py\"\u001b[0m, line \u001b[0;32m59\u001b[0m, in \u001b[0;35mminimize\u001b[0m\n    best_run, space = base_minimizer(model=model,\n",
      "  File \u001b[0;32m\"C:\\Users\\aranc\\AppData\\Roaming\\Python\\Python38\\site-packages\\hyperas\\optim.py\"\u001b[0m, line \u001b[0;32m98\u001b[0m, in \u001b[0;35mbase_minimizer\u001b[0m\n    model_str = get_hyperopt_model_string(model, data, functions, notebook_name, verbose, stack)\n",
      "  File \u001b[0;32m\"C:\\Users\\aranc\\AppData\\Roaming\\Python\\Python38\\site-packages\\hyperas\\optim.py\"\u001b[0m, line \u001b[0;32m189\u001b[0m, in \u001b[0;35mget_hyperopt_model_string\u001b[0m\n    imports = extract_imports(cleaned_source, verbose)\n",
      "  File \u001b[0;32m\"C:\\Users\\aranc\\AppData\\Roaming\\Python\\Python38\\site-packages\\hyperas\\utils.py\"\u001b[0m, line \u001b[0;32m40\u001b[0m, in \u001b[0;35mextract_imports\u001b[0m\n    tree = ast.parse(source)\n",
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\aranc\\anaconda3\\lib\\ast.py\"\u001b[1;36m, line \u001b[1;32m47\u001b[1;36m, in \u001b[1;35mparse\u001b[1;36m\u001b[0m\n\u001b[1;33m    return compile(source, filename, mode, flags,\u001b[0m\n",
      "\u001b[1;36m  File \u001b[1;32m\"<unknown>\"\u001b[1;36m, line \u001b[1;32m484\u001b[0m\n\u001b[1;33m    Evalutation of best performing model:\u001b[0m\n\u001b[1;37m                ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def create_model(a_train, b_train, c_test, d_test):\n",
    "    \"\"\"\n",
    "    Model providing function:\n",
    "\n",
    "    Create Keras model with double curly brackets dropped-in as needed.\n",
    "    Return value has to be a valid python dictionary with two customary keys:\n",
    "        - loss: Specify a numeric evaluation metric to be minimized\n",
    "        - status: Just use STATUS_OK and see hyperopt documentation if not feasible\n",
    "    The last one is optional, though recommended, namely:\n",
    "        - model: specify the model just created so that we can later use it again.\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=1000, return_sequences=True))\n",
    "    model.add(Dropout({{uniform(0, 1)}}))\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation({{choice(['relu', 'sigmoid'])}}))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', metrics=['accuracy'],\n",
    "                  optimizer={{choice(['rmsprop', 'adam', 'sgd'])}})\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=4)\n",
    "    checkpointer = ModelCheckpoint(filepath='keras_weights.hdf5',\n",
    "                                   verbose=1,\n",
    "                                   save_best_only=True)\n",
    "\n",
    "    result = model.fit(a_train,\n",
    "                       b_train,\n",
    "                       batch_size={{choice([32, 64, 128])}},\n",
    "                       epochs=100,\n",
    "                       verbose=2)\n",
    "    \n",
    "\n",
    "    score, acc = model.evaluate(c_test, d_test, verbose=2)\n",
    "\n",
    "    print('Test accuracy:', acc)\n",
    "    return {'loss': -acc, 'status': STATUS_OK, 'model': model}\n",
    "\n",
    "\n",
    "best_run, best_model = optim.minimize(model=create_model,\n",
    "                                      data=data,\n",
    "                                      algo=tpe.suggest,\n",
    "                                      max_evals=20,\n",
    "                                      trials=Trials(),\n",
    "                                      notebook_name='LSTM')\n",
    "\n",
    "a_train, b_train, c_test, d_test = data()\n",
    "print(\"Evalutation of best performing model:\")\n",
    "print(best_model.evaluate(c_test, d_test))\n",
    "print(\"Best performing model chosen hyper-parameters:\")\n",
    "print(best_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = read_csv('data/test.csv', index_col='Date')\n",
    "X = dataset.drop(labels=['close', 'close_nextday'], axis=1)\n",
    "y = dataset['close_nextday']\n",
    "values_x = X.values\n",
    "values_y = y.values\n",
    "values_y = values_y.reshape(-1, 1)\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_data_X = scaler.fit_transform(values_x)\n",
    "scaled_data_y = scaler.fit_transform(values_y)\n",
    "\n",
    "X_train = scaled_data_X[:int(X.shape[0] * 0.8)]\n",
    "X_test = scaled_data_X[int(y.shape[0] * 0.8):]\n",
    "y_train = scaled_data_y[:int(X.shape[0] * 0.8)]\n",
    "y_test = scaled_data_y[int(y.shape[0] * 0.8):]\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], 1, X_train.shape[1])\n",
    "X_test = X_test.reshape(X_test.shape[0], 1, X_test.shape[1])\n",
    "y_train = y_train.reshape(y_train.shape[0], 1, 1)\n",
    "y_test = y_test.reshape(y_test.shape[0], 1, 1)\n",
    "\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_train, b_train, c_test, d_test = [], [], [], []\n",
    "for i in range(1, y_train.shape[0]):\n",
    "    a_train.append(X_train[i - 2:i, 0])\n",
    "    b_train.append(y_train[i, 0])\n",
    "for x in range(1, y_test.shape[0]):\n",
    "    c_test.append(X_test[x - 2:x, 0])\n",
    "    d_test.append(y_test[x, 0])\n",
    "    \n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "print('a, b, c, d')\n",
    "print(a_train.shape)\n",
    "print(b_train.shape)\n",
    "print(c_test.shape)\n",
    "print(d_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_train, b_train, c_test, d_test = np.array(a_train), np.array(b_train), np.array(c_test), np.array(d_test)\n",
    "a_train = np.reshape(a_train, (a_train.shape[0], a_train.shape[1], 6))\n",
    "b_train = np.reshape(b_train, (b_train.shape[0], b_train.shape[1]))\n",
    "c_test = np.reshape(c_test, (c_test.shape[0], c_test.shape[1], 6))\n",
    "d_test = np.reshape(d_test, (d_test.shape[0], d_test.shape[1]))\n",
    "\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "print('a, b, c, d')\n",
    "print(a_train.shape)\n",
    "print(b_train.shape)\n",
    "print(c_test.shape)\n",
    "print(d_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = best_model.predict(c_test)\n",
    "print(yhat.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1]))\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "print('a, b, c, d')\n",
    "print(a_train.shape)\n",
    "print(b_train.shape)\n",
    "print(c_test.shape)\n",
    "print(d_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_yhat = concatenate((yhat, X_test[2:, 1:]), axis=1)\n",
    "inv_yhat = scaler.inverse_transform(inv_yhat)\n",
    "inv_yhat = inv_yhat[:, 0]\n",
    "\n",
    "y_test = y_test.reshape((y_test.shape[0], y_test.shape[1]))\n",
    "inv_y = concatenate((y_test[2:], X_test[2:, 1:]), axis=1)\n",
    "inv_y = scaler.inverse_transform(inv_y)\n",
    "inv_y = inv_y[:, 0]\n",
    "rmse = np.sqrt(mean_squared_error(inv_y, inv_yhat))\n",
    "print('Test RMSE: %.3f' % rmse)\n",
    "\n",
    "_ = plt.figure(figsize=(10, 6))\n",
    "_ = plt.plot(inv_y)\n",
    "_ = plt.plot(inv_yhat)\n",
    "_ = plt.legend([\"actual\", \"pred\"])\n",
    "plt.show()\n",
    "\n",
    "print(min(inv_y), max(inv_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Evalutation of best performing model:\n",
    "3/3 [==============================] - ETA: 0s - loss: 0.6978 - accuracy: 0.0000e+ - 0s 5ms/step - loss: 0.6736 - accuracy: 0.0114\n",
    "[0.6736130118370056, 0.011363636702299118]\n",
    "Best performing model chosen hyper-parameters:\n",
    "{'Activation': 0, 'Dropout': 0.21280043312755825, 'batch_size': 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Evalutation of best performing model:\n",
    "3/3 [==============================] - ETA: 0s - loss: 0.7025 - accuracy: 0.0000e+ - 0s 7ms/step - loss: 0.6327 - accuracy: 0.0114\n",
    "[0.6327084302902222, 0.011363636702299118]\n",
    "Best performing model chosen hyper-parameters:\n",
    "{'Activation': 0, 'Dropout': 0.21280043312755825, 'batch_size': 2}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
