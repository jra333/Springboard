{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "\n",
    "from hyperopt import Trials, STATUS_OK, tpe\n",
    "from hyperas import optim\n",
    "from hyperas.distributions import choice, uniform\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "def data():\n",
    "    \n",
    "    dataset = read_csv('data/train.csv', index_col='Date')\n",
    "    \n",
    "    X = dataset.drop(labels=['close_nextday', 'close'], axis=1)\n",
    "    y = dataset['close_nextday']\n",
    "    \n",
    "    \n",
    "    tss = TimeSeriesSplit(n_splits=3)  # n_splits = 3-1...2 splits - 75% train, 25% test\n",
    "\n",
    "    for train_index, test_index in tss.split(X):\n",
    "        X_train, X_test = X.iloc[train_index, :], X.iloc[test_index, :]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        \n",
    "    # Reshape y train, test to match X train, test\n",
    "\n",
    "    y_train = y_train.values.reshape(-1, 1)\n",
    "    y_test = y_test.values.reshape(-1, 1)\n",
    "    \n",
    "    \n",
    "    ss = StandardScaler()\n",
    "\n",
    "    X_train = ss.fit_transform(X_train)\n",
    "    X_test = ss.fit_transform(X_test)\n",
    "    y_train = ss.fit_transform(y_train)\n",
    "    y_test = ss.fit_transform(y_test)\n",
    "    \n",
    "    X_train = X_train.reshape(X_train.shape[0], 1, X_train.shape[1])\n",
    "    X_test = X_test.reshape(X_test.shape[0], 1, X_test.shape[1])\n",
    "    y_train = y_train.reshape(y_train.shape[0], 1, 1)\n",
    "    y_test = y_test.reshape(y_test.shape[0], 1, 1)\n",
    "    \n",
    "    n_features = X.shape[1]\n",
    "    n_input = y.shape[0]\n",
    "    \n",
    "    print(n_features)\n",
    "    print(n_input)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Imports:\n",
      "#coding=utf-8\n",
      "\n",
      "from __future__ import print_function\n",
      "\n",
      "try:\n",
      "    import numpy as np\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperopt import Trials, STATUS_OK, tpe\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperas import optim\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperas.distributions import choice, uniform\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.preprocessing import sequence\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.models import Sequential\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.layers.core import Dense, Dropout, Activation\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.layers.embeddings import Embedding\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.layers.recurrent import LSTM\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.utils import np_utils\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from pandas import read_csv\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.model_selection import TimeSeriesSplit\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.preprocessing import StandardScaler\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.preprocessing import MinMaxScaler\n",
      "except:\n",
      "    pass\n",
      "\n",
      "from __future__ import print_function\n",
      "\n",
      "try:\n",
      "    import numpy as np\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperopt import Trials, STATUS_OK, tpe\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperas import optim\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperas.distributions import choice, uniform\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.preprocessing import sequence\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.models import Sequential\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.layers.core import Dense, Dropout, Activation\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.layers.embeddings import Embedding\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.layers.recurrent import LSTM\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.utils import np_utils\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from pandas import read_csv\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.model_selection import TimeSeriesSplit\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.preprocessing import StandardScaler\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.preprocessing import MinMaxScaler\n",
      "except:\n",
      "    pass\n",
      "\n",
      ">>> Hyperas search space:\n",
      "\n",
      "def get_space():\n",
      "    return {\n",
      "        'Activation': hp.choice('Activation', ['relu', 'sigmoid', 'linear', 'softmax']),\n",
      "        'Dropout': hp.uniform('Dropout', 0, 1),\n",
      "        'optimizer': hp.choice('optimizer', ['rmsprop', 'adam', 'sgd', 'nadam']),\n",
      "        'batch_size': hp.choice('batch_size', [12, 24, 64, 128]),\n",
      "        'epochs': hp.choice('epochs', [100, 200, 300, 400, 500]),\n",
      "    }\n",
      "\n",
      ">>> Data\n",
      "  1: \n",
      "  2: \n",
      "  3: dataset = read_csv('data/train.csv', index_col='Date')\n",
      "  4: \n",
      "  5: X = dataset.drop(labels=['close_nextday', 'close'], axis=1)\n",
      "  6: y = dataset['close_nextday']\n",
      "  7: \n",
      "  8: \n",
      "  9: tss = TimeSeriesSplit(n_splits=3)  # n_splits = 3-1...2 splits - 75% train, 25% test\n",
      " 10: \n",
      " 11: for train_index, test_index in tss.split(X):\n",
      " 12:     X_train, X_test = X.iloc[train_index, :], X.iloc[test_index, :]\n",
      " 13:     y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
      " 14:     \n",
      " 15: # Reshape y train, test to match X train, test\n",
      " 16: \n",
      " 17: y_train = y_train.values.reshape(-1, 1)\n",
      " 18: y_test = y_test.values.reshape(-1, 1)\n",
      " 19: \n",
      " 20: \n",
      " 21: ss = StandardScaler()\n",
      " 22: \n",
      " 23: X_train = ss.fit_transform(X_train)\n",
      " 24: X_test = ss.fit_transform(X_test)\n",
      " 25: y_train = ss.fit_transform(y_train)\n",
      " 26: y_test = ss.fit_transform(y_test)\n",
      " 27: \n",
      " 28: X_train = X_train.reshape(X_train.shape[0], 1, X_train.shape[1])\n",
      " 29: X_test = X_test.reshape(X_test.shape[0], 1, X_test.shape[1])\n",
      " 30: y_train = y_train.reshape(y_train.shape[0], 1, 1)\n",
      " 31: y_test = y_test.reshape(y_test.shape[0], 1, 1)\n",
      " 32: \n",
      " 33: n_features = X.shape[1]\n",
      " 34: n_input = y.shape[0]\n",
      " 35: \n",
      " 36: \n",
      " 37: \n",
      " 38: \n",
      ">>> Resulting replaced keras model:\n",
      "\n",
      "  1: def keras_fmin_fnct(space):\n",
      "  2: \n",
      "  3: \n",
      "  4:     model = Sequential()\n",
      "  5:     model.add(LSTM(128, input_shape=(n_input, n_features)))\n",
      "  6:     model.add(Activation(space['Activation']))\n",
      "  7:     model.add(Dropout(space['Dropout']))\n",
      "  8:     model.add(Dense(1))\n",
      "  9: \n",
      " 10:     model.compile(loss='mse',\n",
      " 11:                   optimizer=space['optimizer'],\n",
      " 12:                   metrics=['mse'])\n",
      " 13: \n",
      " 14:     result = model.fit(X_train,\n",
      " 15:                        y_train,\n",
      " 16:                        batch_size=space['batch_size'],\n",
      " 17:                        epochs=space['epochs'],\n",
      " 18:                        verbose=2,\n",
      " 19:                        validation_data=(X_test, y_test))\n",
      " 20:                        \n",
      " 21: \n",
      " 22:     score, mse = model.evaluate(X_test, y_test, verbose=0)\n",
      " 23:     print('Test accuracy:', mse)\n",
      " 24:     return {'loss': mse, 'status': STATUS_OK, 'model': model}\n",
      " 25: \n",
      "Unexpected error: <class 'SyntaxError'>\n"
     ]
    },
    {
     "ename": "SyntaxError",
     "evalue": "from __future__ imports must occur at the beginning of the file (temp_model.py, line 80)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[1;36m(most recent call last)\u001b[0m:\n",
      "  File \u001b[0;32m\"C:\\Users\\aranc\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\"\u001b[0m, line \u001b[0;32m3418\u001b[0m, in \u001b[0;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \u001b[0;32m\"<ipython-input-2-0ee39e94b5bb>\"\u001b[0m, line \u001b[0;32m85\u001b[0m, in \u001b[0;35m<module>\u001b[0m\n    best_run, best_model = optim.minimize(model=model,\n",
      "  File \u001b[0;32m\"C:\\Users\\aranc\\anaconda3\\lib\\site-packages\\hyperas\\optim.py\"\u001b[0m, line \u001b[0;32m59\u001b[0m, in \u001b[0;35mminimize\u001b[0m\n    best_run, space = base_minimizer(model=model,\n",
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\aranc\\anaconda3\\lib\\site-packages\\hyperas\\optim.py\"\u001b[1;36m, line \u001b[1;32m106\u001b[1;36m, in \u001b[1;35mbase_minimizer\u001b[1;36m\u001b[0m\n\u001b[1;33m    from temp_model import keras_fmin_fnct, get_space\u001b[0m\n",
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\aranc\\Documents\\SpringboardClass\\Capstone Project 2\\temp_model.py\"\u001b[1;36m, line \u001b[1;32m80\u001b[0m\n\u001b[1;33m    from __future__ import print_function\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m from __future__ imports must occur at the beginning of the file\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "\n",
    "from hyperopt import Trials, STATUS_OK, tpe\n",
    "from hyperas import optim\n",
    "from hyperas.distributions import choice, uniform\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "def data():\n",
    "    \n",
    "    dataset = read_csv('data/train.csv', index_col='Date')\n",
    "    \n",
    "    X = dataset.drop(labels=['close_nextday', 'close'], axis=1)\n",
    "    y = dataset['close_nextday']\n",
    "    \n",
    "    \n",
    "    tss = TimeSeriesSplit(n_splits=3)  # n_splits = 3-1...2 splits - 75% train, 25% test\n",
    "\n",
    "    for train_index, test_index in tss.split(X):\n",
    "        X_train, X_test = X.iloc[train_index, :], X.iloc[test_index, :]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        \n",
    "    # Reshape y train, test to match X train, test\n",
    "\n",
    "    y_train = y_train.values.reshape(-1, 1)\n",
    "    y_test = y_test.values.reshape(-1, 1)\n",
    "    \n",
    "    \n",
    "    ss = StandardScaler()\n",
    "\n",
    "    X_train = ss.fit_transform(X_train)\n",
    "    X_test = ss.fit_transform(X_test)\n",
    "    y_train = ss.fit_transform(y_train)\n",
    "    y_test = ss.fit_transform(y_test)\n",
    "    \n",
    "    X_train = X_train.reshape(X_train.shape[0], 1, X_train.shape[1])\n",
    "    X_test = X_test.reshape(X_test.shape[0], 1, X_test.shape[1])\n",
    "    y_train = y_train.reshape(y_train.shape[0], 1, 1)\n",
    "    y_test = y_test.reshape(y_test.shape[0], 1, 1)\n",
    "    \n",
    "    n_features = X.shape[1]\n",
    "    n_input = y.shape[0]\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def model(X_train, X_test, y_train, y_test):\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(128, input_shape=(n_input, n_features)))\n",
    "    model.add(Activation({{choice(['relu', 'sigmoid', 'linear', 'softmax'])}}))\n",
    "    model.add(Dropout({{uniform(0, 1)}}))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    model.compile(loss='mse',\n",
    "                  optimizer={{choice(['rmsprop', 'adam', 'sgd', 'nadam'])}},\n",
    "                  metrics=['mse'])\n",
    "\n",
    "    result = model.fit(X_train,\n",
    "                       y_train,\n",
    "                       batch_size={{choice([12, 24, 64, 128])}},\n",
    "                       epochs={{choice([100, 200, 300, 400, 500])}},\n",
    "                       verbose=2,\n",
    "                       validation_data=(X_test, y_test))\n",
    "                       \n",
    "\n",
    "    score, mse = model.evaluate(X_test, y_test, verbose=0)\n",
    "    print('Test accuracy:', mse)\n",
    "    return {'loss': mse, 'status': STATUS_OK, 'model': model}\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    trials = Trials()\n",
    "    best_run, best_model = optim.minimize(model=model,\n",
    "                                          data=data,\n",
    "                                          algo=tpe.suggest,\n",
    "                                          max_evals=10,\n",
    "                                          trials=trials,\n",
    "                                          notebook_name=\"LSTM\")\n",
    "    \n",
    "    for trial in trials:\n",
    "        print(trial)\n",
    "    \n",
    "    X_train, y_train, X_test, y_test = data()\n",
    "    print(\"Evalutation of best performing model:\")\n",
    "    print(best_model.evaluate(X_test, y_test)) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
